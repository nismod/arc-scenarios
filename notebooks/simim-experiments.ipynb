{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore migration scaling, parameter uplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import simim.data_apis\n",
    "\n",
    "from ukpopulation.myedata import MYEData\n",
    "from ukpopulation.nppdata import NPPData\n",
    "from ukpopulation.snppdata import SNPPData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [os.path.split(p.replace('../simim/data/output\\\\', '')) for p in glob.glob('../simim/data/output/**/*.csv')]\n",
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lads = gpd.read_file('../simim/data/cache/Local_Authority_Districts_December_2016_Ultra_Generalised_Clipped_Boundaries_in_Great_Britain.shp') \\\n",
    "    .drop(['objectid', 'lad16nmw', 'bng_e', 'bng_n', 'long', 'lat', 'st_lengths'], axis=1)\n",
    "lads.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_lads = pd.read_csv('../simim/data/scenarios/camkox_lads.csv')\n",
    "arc_lads.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_baseline(arc_lads):\n",
    "    # households\n",
    "    os.chdir(\"../simim\")\n",
    "    simim_data = simim.data_apis.Instance({\n",
    "        \"coverage\": \"GB\", \n",
    "        \"cache_dir\": \"./data/cache\", \n",
    "        \"output_dir\": \"./data/output\",\n",
    "        \"model_type\": \"none\",\n",
    "        \"base_projection\": \"ppp\",\n",
    "        \"scenario\": \"none\",\n",
    "        \"attractors\": []\n",
    "    })\n",
    "    dfs = []\n",
    "    for year in range(2015, 2051):\n",
    "        df = simim_data.get_households(year, lads.lad16cd.unique())\n",
    "        dfs.append(df)\n",
    "    households = pd.concat(dfs, sort=False).rename(columns={\"PROJECTED_YEAR_NAME\": \"YEAR\"})\n",
    "    \n",
    "    \n",
    "    # population\n",
    "    lad_cds = list(arc_lads.geo_code.unique())\n",
    "    mye = MYEData()\n",
    "    years = [2015]\n",
    "    pop_mye = mye.aggregate([\"GENDER\", \"C_AGE\"], lad_cds, years)\n",
    "\n",
    "    npp = NPPData()\n",
    "    snpp = SNPPData()\n",
    "    snpp_years = [2030]\n",
    "    extra_years = [2050]\n",
    "    pop_snpp = snpp.aggregate([\"GENDER\", \"C_AGE\"], lad_cds, snpp_years)\n",
    "    pop_ex = snpp.extrapolagg([\"GENDER\", \"C_AGE\"], npp, lad_cds, extra_years)\n",
    "    pop = pd.concat([pop_mye, pop_snpp, pop_ex], axis=0) \\\n",
    "        .rename(columns={'OBS_VALUE':'PEOPLE', 'PROJECTED_YEAR_NAME': 'YEAR'})\n",
    "    pop.PEOPLE = pop.PEOPLE.astype(int)\n",
    "    # merge later (after subset everything else)\n",
    "    \n",
    "    os.chdir(\"../notebooks\")\n",
    "    \n",
    "    # employment, gva, dwellings\n",
    "    df_emp = pd.read_csv(\"../simim/data/arc/arc_employment__baseline.csv\")\n",
    "    df_gva = pd.read_csv(\"../simim/data/arc/arc_gva__baseline.csv\")\n",
    "    df_dwl = pd.read_csv(\"../simim/data/arc/arc_dwellings__baseline.csv\")\n",
    "\n",
    "    # merge to single dataframe\n",
    "    df = df_gva \\\n",
    "      .merge(df_emp, on=[\"timestep\", \"lad_uk_2016\"], how=\"left\") \\\n",
    "      .merge(df_dwl, on=[\"timestep\", \"lad_uk_2016\"], how=\"left\")\n",
    "\n",
    "    baseline = df.reset_index().rename(columns={\n",
    "        \"timestep\": \"YEAR\", \n",
    "        \"lad_uk_2016\": \"GEOGRAPHY_CODE\", \n",
    "        \"employment\": \"JOBS\", \n",
    "        \"gva\": \"GVA\", \n",
    "        \"gva_per_sector\": \"GVA\",\n",
    "        \"dwellings\": \"DWELLINGS\"\n",
    "    })[[\n",
    "     \"YEAR\", \"GEOGRAPHY_CODE\", \"JOBS\", \"GVA\", \"DWELLINGS\"\n",
    "    ]].merge(\n",
    "      households, on=[\"GEOGRAPHY_CODE\", \"YEAR\"]\n",
    "    )\n",
    "    baseline[\"GVA\"] = baseline[\"GVA\"].round(6)\n",
    "    # convert from 1000s jobs to jobs\n",
    "    baseline[\"JOBS\"] = (baseline[\"JOBS\"] * 1000).round().astype(int)\n",
    "    \n",
    "    baseline = baseline[\n",
    "        baseline.GEOGRAPHY_CODE.isin(arc_lads.geo_code)        \n",
    "        & baseline.YEAR.isin([2015, 2030, 2050])\n",
    "    ]\n",
    "    baseline = baseline \\\n",
    "        .merge(pop, on=['GEOGRAPHY_CODE','YEAR']) \\\n",
    "        .merge(arc_lads, left_on='GEOGRAPHY_CODE', right_on='geo_code') \\\n",
    "        .drop(['geo_code'], axis=1) \\\n",
    "        .rename(columns={'geo_label':'GEOGRAPHY_NAME'})\n",
    "    \n",
    "    baseline['SCENARIO'] = 'baseline'\n",
    "    \n",
    "    return baseline\n",
    "\n",
    "baseline = read_baseline(arc_lads)\n",
    "\n",
    "len(baseline.YEAR.unique()), len(baseline.GEOGRAPHY_CODE.unique()), len(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output_and_scenario(arc_lads, baseline, scenario_key, output_path):\n",
    "    key = scenario_key\n",
    "    \n",
    "    if key == \"3-new-cities23\":\n",
    "        econ_key = \"1-new-cities\"\n",
    "    elif key == \"4-expansion23\":\n",
    "        econ_key = \"2-expansion\"\n",
    "    else:\n",
    "        econ_key = key\n",
    "        \n",
    "    df_gva = pd.read_csv(\"../simim/data/arc/arc_gva__{}.csv\".format(econ_key))\n",
    "    df_emp = pd.read_csv(\"../simim/data/arc/arc_employment__{}.csv\".format(econ_key))\n",
    "    df_dwl = pd.read_csv(\"../simim/data/arc/arc_dwellings__{}.csv\".format(key))\n",
    "    \n",
    "    # merge to single dataframe\n",
    "    scenario = df_gva \\\n",
    "    .merge(df_emp, on=[\"timestep\", \"lad_uk_2016\"], how=\"left\") \\\n",
    "    .merge(df_dwl, on=[\"timestep\", \"lad_uk_2016\"], how=\"left\") \\\n",
    "    .drop(\"lad16nm\", axis=1) \\\n",
    "    .rename(columns={\n",
    "        \"timestep\": \"YEAR\", \n",
    "        \"lad_uk_2016\": \"GEOGRAPHY_CODE\", \n",
    "        \"gva_per_sector\": \"GVA\",\n",
    "        \"employment\": \"JOBS\",  \n",
    "        \"dwellings\": \"HOUSEHOLDS\"})\n",
    "    \n",
    "    scenario = scenario.merge(arc_lads, left_on='GEOGRAPHY_CODE', right_on='geo_code') \\\n",
    "        .drop(['geo_code'], axis=1) \\\n",
    "        .rename(columns={'geo_label':'GEOGRAPHY_NAME'})\n",
    "    \n",
    "    scenario = scenario[\n",
    "        scenario.GEOGRAPHY_CODE.isin(arc_lads.geo_code)\n",
    "        & scenario.YEAR.isin([2015, 2030, 2050])\n",
    "    ]\n",
    "    \n",
    "    # rebase scenario households (dwelling) numbers on baseline households - this is what simim sees as input\n",
    "    scenario = scenario.merge(baseline[['YEAR','GEOGRAPHY_CODE','DWELLINGS','HOUSEHOLDS']], on=['YEAR','GEOGRAPHY_CODE'])\n",
    "    scenario.HOUSEHOLDS_x = scenario.HOUSEHOLDS_x - scenario.DWELLINGS + scenario.HOUSEHOLDS_y\n",
    "    scenario = scenario.drop(['HOUSEHOLDS_y'], axis=1).rename(columns={'HOUSEHOLDS_x':'HOUSEHOLDS'})    \n",
    "    \n",
    "    scenario.GVA = scenario.GVA.round(6)\n",
    "    scenario.JOBS = (scenario.JOBS * 1000).round().astype(int)  # convert from 1000s jobs to jobs\n",
    "    scenario.HOUSEHOLDS = scenario.HOUSEHOLDS.round().astype(int)\n",
    "    \n",
    "    output = pd.read_csv(os.path.join(output_path)) \\\n",
    "    .rename(columns={'PROJECTED_YEAR_NAME': 'YEAR'})\n",
    "    \n",
    "    output = scenario.merge(output, on=[\"YEAR\", \"GEOGRAPHY_CODE\"], how='left') \\\n",
    "        .drop(['PEOPLE_SNPP', 'RELATIVE_DELTA'], axis=1)\n",
    "    \n",
    "    output['SCENARIO'] = scenario_key\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline['EXPERIMENT'] = 'baseline'\n",
    "dfs = [baseline]\n",
    "for experiment, result in paths:\n",
    "    if 'od_rail' not in result:\n",
    "        continue\n",
    "        \n",
    "    path = os.path.join('../simim/data/output', experiment, result)\n",
    "    \n",
    "    # regex to find scenario\n",
    "    m = re.search(r'scenario([^_]+)', path)\n",
    "    if m:\n",
    "        scen = m.group(1)\n",
    "    else:\n",
    "        scen = path\n",
    "        \n",
    "    df = read_output_and_scenario(arc_lads, baseline, scen, path)\n",
    "    df.pivot(index='YEAR',columns='GEOGRAPHY_NAME', values='PEOPLE').plot(\n",
    "        title=experiment + ' ' + scen\n",
    "    )\n",
    "    df['EXPERIMENT'] = experiment\n",
    "    \n",
    "    dfs.append(df)\n",
    "        \n",
    "dataset = pd.concat(dfs, axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['PPH'] = dataset.PEOPLE / dataset.HOUSEHOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset.PPH < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = dataset.groupby([\"YEAR\",'SCENARIO', 'EXPERIMENT']).sum()\n",
    "summary.PPH = summary.PEOPLE / summary.HOUSEHOLDS\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary.reset_index()\n",
    "summary = summary.merge(\n",
    "        summary[summary.SCENARIO == 'baseline'][['YEAR','PPH']], \n",
    "        on='YEAR', how='left', suffixes=('','_BASELINE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['EXP_POP'] = summary.HOUSEHOLDS * summary.PPH_BASELINE\n",
    "summary['PEOPLE_SCALE_FACTOR'] = summary.EXP_POP / summary.PEOPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.merge(\n",
    "    summary[['YEAR','SCENARIO', 'EXPERIMENT', 'PEOPLE_SCALE_FACTOR']], \n",
    "    on=['YEAR','SCENARIO','EXPERIMENT'], how='left')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['SCALED_PEOPLE'] = dataset.PEOPLE * dataset.PEOPLE_SCALE_FACTOR\n",
    "dataset['SCALED_PPH'] = dataset.SCALED_PEOPLE / dataset.HOUSEHOLDS\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset.SCALED_PPH < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = dataset.pivot_table(index=['GEOGRAPHY_CODE','GEOGRAPHY_NAME','YEAR'], columns=['EXPERIMENT', 'SCENARIO'])\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.to_csv('scaled_factor_experiments.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
